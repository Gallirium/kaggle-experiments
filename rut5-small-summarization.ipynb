{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efef074b-4c22-4043-8b3d-6b123898f79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallirium/dostNN/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import evaluate\n",
    "## nltk для бейзлайновой модели\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f353ff6-b8a3-4bd1-b9ba-0fa72f2c2cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model_name = 'cointegrated/rut5-small'\n",
    "dataset = load_dataset('IlyaGusev/gazeta', revision=\"v2.0\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9491b51b-d880-405a-8712-e7b2d319fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Это вообще что такое??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa21e7c0-432f-4800-95be-aeae1e8ff9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁', 'Это', '▁в', 'ообще', '▁что', '▁тако', 'е', '??', '</s>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23f76133-4921-47e2-b219-628da0608af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dset):\n",
    "    model_inputs = tokenizer(dset['text'], max_length=512, truncation=True)\n",
    "    labels = tokenizer(dset['summary'], max_length=50, truncation=True)\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43c27b2d-7fca-46aa-b1fa-23148632aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_dset = dataset.map(process,batched=True)\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1def67de-3456-4455-8337-7e4c749e51a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_sentences(text):\n",
    "    return '\\n'.join(sent_tokenize(text)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50623600-d576-4c5b-abe7-94ace5b960a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Словосочетание «музыкальный кинофестиваль» уже не звучит непривычным оксюмороном — в наше бедное на гениев время разобраться в современной музыке порой проще с помощью наблюдения за участниками процесса.\\nТак уже было, к примеру, с сандэнсовским фильмом «DiG!», влюбившим зрителей по всему миру в портлендского безумца Антона Ньюкомба и его группу Brian Jonestown Massacre.\\nВ столице картину показали год назад.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_sentences(dataset['train'][1]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff38f5e6-5fc2-4448-967f-5df3198a7655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Словосочетание «музыкальный кинофестиваль» уже не звучит непривычным оксюмороном — в наше бедное на гениев время разобраться в современной музыке порой проще с помощью наблюдения за участниками процесса. Так уже было, к примеру, с сандэнсовским фильмом «DiG!», влюбившим зрителей по всему миру в портлендского безумца Антона Ньюкомба и его группу Brian Jonestown Massacre. В столице картину показали год назад. Это был совсем камерный клубный показ в рамках фестиваля Music.doc, почти без рекламы, но о тех двух часах не пожалел никто из пары десятков случайных и не очень посетителей. То же можно сказать и о прочих показах. Стартующий в этот четверг Beat Film Festival – прямой наследник Music.doc. На этот раз к услугам киномеломанов самая авторитетная арт-хаусная площадка города, а не тесный клуб или помпезный «Иллюзион», а вместо собранной по сусекам программы – фильмы с не более чем двухлетним сроком давности. Картины «Bassweight» и «Favellla on Blast» рассказывают (соответственно) о все еще свежих дабстепе и балеарике – направлениях, с которыми сейчас принято связывать будущее электронной (и не только) музыки. Произведения львиной доли адептов этих стилей вне удолбанного танцпола или хотя бы прокуренного клуба приводят к внезапным вспышкам головной боли, однако породившая их среда, безусловно, заслуживает внимательно взгляда. Почему дабстеп появился в Лондоне, а балеарик – в бразильских фавеллах? Почему герои дабстепа прячут лица, а M.I.A., напротив, носит яркие лосины? Ну и главный вопрос – как секс, наркотики, густой смог и вечное похмелье конденсируют в музыку? О субкультуре другого порядка рассказывает картина «Taqwacore: The Birth of Punk Islam». Вынесенное в заглавие слово придумал писатель Майкл Мухаммед Найт для своего романа о нью-йоркских панках-мусульманах The Taqwacores. Выдуманный стиль дал толчок исламскому панку, стремительное развитие которого и стало причиной появления первого посвященного этому явлению фильма. Главным героем картины, как можно догадаться, стал сам писатель. Наш личный фаворит программы. Мостом между мейнстримовой и андеграундной культурами служит летопись двух фестивалей – московского «Пикника «Афиши»» и лондонского All Tomorrow's Parties. Если про первый все и так известно, история второго для многих станет открытием. Один из важнейших британских фестивалей славится не только своей демократичностью, но и тем, что его кураторами ежегодно становятся главные герои мировой альтернативной сцены – от Ника Кейва до Portishead. У посетителей Beat Film Festival есть шанс почувствовать всю прелесть этого предприятия – часть фильма смонтирована из любительской «мобилографии». Ну и, наконец, не обойдется и без знакомых широкой публике имен. Самой близкой россиянам картиной должна стать «Posters Came From The Walls» — рассказ о фанатах Depeche Mode по всему миру, не обошедший вниманием и некогда многочисленное российское фанатское коммьюнити. Другим потенциальным хитом программы может стать «No Distance Left To Run» — новейший извод истории группы Blur от рождения до последнего концерта в Гластонберри годичной давности. Впрочем, поговаривают, что и он был не последним, но это уже совсем другая история. Ну а откроется фестиваль в четверг фильмом «Stones in Exile», который в представлениях для сведущей публики, в общем, не нуждается. Это хроника года, проведенного группой The Rolling Stones в Париже во время записи недавно переизданного альбома «Exile On Main Street» — одной из лучших и точно самой безумной записи великих британцев. Иными словами, документальное свидетельство тех времен, когда изобретатель формулы «Секс, наркотики и рок-н-ролл» Мик Джаггер и его одногруппники в полной мере убеждали в действенности изобретенной идеологии. И прежде чем спрашивать, где же тут актуальность, стоит полюбопытствовать, что в их жизни изменилось с тех пор. The Beat Film Festival пройдет в кинотеатре 35 мм с 3 по 8 июня.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fdd904d-9f90-47e6-bd4f-12887f8a5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "## baseline three-sentence summarization\n",
    "summaries = [three_sentences(text) for text in dataset['train'][:]['text']]\n",
    "results = rouge.compute(predictions=summaries, references=dataset['train'][:]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1728a997-db3c-4446-a18e-95d80a0fa616",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {k: round(v*100,2) for k, v in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cd73af0-1649-4ab6-a2e5-b3ff118abea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 17.45, 'rouge2': 5.24, 'rougeL': 16.89, 'rougeLsum': 16.93}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82514dc4-16a6-43e4-b956-5dff83607c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f88c9ae3-e840-4b4d-8cbb-1bff6c0a25af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def metrics(p):\n",
    "    preds, labels = p\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds = ['\\n'.join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = ['\\n'.join(sent_tokenize(pred.strip())) for label in decoded_labels]\n",
    "\n",
    "    result = rouge_score.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    return {k: round(v*100, 2) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4aa9ccbb-e16b-4c24-8ea7-bf3e9e13dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "tok_dset_test = tok_dset.remove_columns(['text','summary','title','url','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6372b0a9-ed91-4fe6-84a5-6f0ef7810de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 8\n",
    "EPOCHS = 2\n",
    "LOGS = len(tok_dset_test['train'])//BS\n",
    "\n",
    "train_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"rut5-base-summarization-practice\",\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=5e-4,\n",
    "    per_device_train_batch_size=BS,\n",
    "    per_device_eval_batch_size=BS,\n",
    "    weight_decay=0.02,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    logging_steps=LOGS,\n",
    "    predict_with_generate=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args = train_args,\n",
    "    train_dataset=tok_dset_test[\"train\"],\n",
    "    eval_dataset=tok_dset_test[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80499be3-c7a8-469f-908d-2debfcd067d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7622' max='15242' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7622/15242 40:10 < 40:10, 3.16 it/s, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='797' max='797' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [797/797 03:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallirium/dostNN/lib/python3.11/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'T5Tokenizer' object has no attribute 'batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dostNN/lib/python3.11/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dostNN/lib/python3.11/site-packages/transformers/trainer.py:1937\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1934\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1937\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   1940\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   1941\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/dostNN/lib/python3.11/site-packages/transformers/trainer.py:2271\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2269\u001b[0m         metrics\u001b[38;5;241m.\u001b[39mupdate(dataset_metrics)\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2271\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/dostNN/lib/python3.11/site-packages/transformers/trainer_seq2seq.py:165\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     gen_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_beams\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgeneration_num_beams\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dostNN/lib/python3.11/site-packages/transformers/trainer.py:3011\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3008\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3010\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3011\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3012\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3014\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3015\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3021\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/dostNN/lib/python3.11/site-packages/transformers/trainer.py:3304\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3300\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3301\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[1;32m   3302\u001b[0m         )\n\u001b[1;32m   3303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3304\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3306\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m, in \u001b[0;36mmetrics\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m      5\u001b[0m decoded_preds \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(preds, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(labels \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m, labels, tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id)\n\u001b[0;32m----> 7\u001b[0m decoded_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(labels, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m decoded_preds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sent_tokenize(pred\u001b[38;5;241m.\u001b[39mstrip())) \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m decoded_preds]\n\u001b[1;32m     10\u001b[0m decoded_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sent_tokenize(pred\u001b[38;5;241m.\u001b[39mstrip())) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m decoded_labels]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'T5Tokenizer' object has no attribute 'batch'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6bea1a-4f09-473c-ac8b-b112a06e9fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db594a35-2c41-4bc8-b975-ada15b9c4d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0df4c6-13d6-4b07-9c03-dbc422ac69ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dostNN",
   "language": "python",
   "name": "dostnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
