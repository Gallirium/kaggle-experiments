{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15286915-b1ca-490b-8dde-42ae4e7f593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 20:55:05.073294: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6af5b9bd-6676-4b6d-99b2-c584b33d6995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13af3b8c-7025-4d3e-ba0d-24f8a3dc2e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(predictions, target):\n",
    "    fpr, tpr, thresholds = roc_curve(target, predictions)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c219b6d-e694-4526-a727-e5cc58f474dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./jigsaw-toxic-comment-train.csv')\n",
    "train.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True)\n",
    "train = train.loc[:12000,:]\n",
    "\n",
    "valid = pd.read_csv('./validation.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9170e53-cfee-48ba-9fb9-4267a46a79bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1403"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'].apply(lambda x: len(str(x).split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4beef4-b2d6-4c52-9bcf-344fe9bef2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    train.comment_text.values, train.toxic.values,\n",
    "    stratify = train.toxic.values,\n",
    "    random_state = 42,\n",
    "    test_size = 0.2, shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20e339db-6cac-4534-ba11-730fa948e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import text\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 1500\n",
    "\n",
    "token.fit_on_texts(list(x_train) + list(x_valid))\n",
    "x_train_seq = token.texts_to_sequences(x_train)\n",
    "x_valid_seq = token.texts_to_sequences(x_valid)\n",
    "\n",
    "x_train_pad = pad_sequences(x_train_seq, maxlen=max_len)\n",
    "x_valid_pad = pad_sequences(x_valid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f565a0fb-b7f8-481f-a603-f1e2596661c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25850823-774a-4774-bfe6-67c937ebb112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [01:25, 25567.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2196016 word embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeds = {}\n",
    "with open('./glove.840B.300d.txt') as f:\n",
    "        for line in tqdm(f):\n",
    "            values = line.split(' ')\n",
    "            word = values[0]\n",
    "            coefs = np.asarray([float(val) for val in values[1:]])\n",
    "            embeds[word] = coefs\n",
    "\n",
    "print(f\"There are {len(embeds)} word embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3334b734-1f89-42ac-8f67-c0ed280421bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 43496/43496 [00:00<00:00, 445527.39it/s]\n"
     ]
    }
   ],
   "source": [
    "##Create matrix for existing words\n",
    "\n",
    "mat = np.zeros((len(word_index)+1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embvec = embeds.get(word)\n",
    "    if embvec is not None:\n",
    "        mat[i] = embvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7732635-8fc3-407a-9f20-bc493f5b305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 20:56:35.109644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 20:56:35.142183: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 20:56:35.142394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 20:56:35.144339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 20:56:35.144684: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 20:56:35.144983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 20:56:35.212713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 20:56:35.212939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 20:56:35.213115: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-15 20:56:35.213248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4250 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-10-15 20:56:35.213554: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1500, 300)         13049100  \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               219648    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,268,877\n",
      "Trainable params: 219,777\n",
      "Non-trainable params: 13,049,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1, 300,\n",
    "                    weights = [mat],\n",
    "                    input_length=max_len,\n",
    "                    trainable=False))\n",
    "model.add(LSTM(128, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "781a151d-717d-43b6-b199-2aac4738fbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 20:56:37.282884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-15 20:56:37.894945: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f974d00d3d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-15 20:56:37.894971: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-10-15 20:56:37.900868: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-15 20:56:37.912715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2023-10-15 20:56:38.011664: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 527s 874ms/step - loss: 0.1784 - accuracy: 0.9405\n",
      "Epoch 2/3\n",
      "600/600 [==============================] - 521s 868ms/step - loss: 0.1303 - accuracy: 0.9545\n",
      "Epoch 3/3\n",
      "600/600 [==============================] - 521s 868ms/step - loss: 0.1119 - accuracy: 0.9611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99b5c3f490>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad, y_train, epochs=3, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e59efcb-5a7c-4967-90ca-40475275f69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 16s 209ms/step\n",
      "AUC: 0.97%\n"
     ]
    }
   ],
   "source": [
    "scores = model.predict(x_valid_pad)\n",
    "print(\"AUC: %.2f%%\" % (roc_auc(scores, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f2b3c67-6436-45db-a46d-6cfaa696f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Jesus this took almost 40 minutes to train why did I decide to do this...\n",
    "## Let's also test out GRUs!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f884c43d-c3a2-4157-ac80-d5c9c4a7981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SpatialDropout1D, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e10a233-0ce1-43e4-9386-caf75ac63f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 1500, 300)         13049100  \n",
      "                                                                 \n",
      " spatial_dropout1d_3 (Spatia  (None, 1500, 300)        0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 300)               541800    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,591,201\n",
      "Trainable params: 542,101\n",
      "Non-trainable params: 13,049,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_gru = Sequential()\n",
    "model_gru.add(Embedding(len(word_index) + 1, 300,\n",
    "             weights = [mat],\n",
    "             input_length = max_len,\n",
    "             trainable = False\n",
    "             ))\n",
    "model_gru.add(SpatialDropout1D(0.3))\n",
    "model_gru.add(GRU(300, recurrent_dropout=0.3))\n",
    "model_gru.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_gru.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eeb1bb5-77a1-4a14-aef9-ce0eea4b5c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "300/300 [==============================] - 256s 848ms/step - loss: 0.1907 - accuracy: 0.9364\n",
      "Epoch 2/3\n",
      "300/300 [==============================] - 254s 847ms/step - loss: 0.1237 - accuracy: 0.9555\n",
      "Epoch 3/3\n",
      "300/300 [==============================] - 256s 853ms/step - loss: 0.1035 - accuracy: 0.9608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f98de59f290>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gru.fit(x_train_pad, y_train, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f389bd51-56ed-4128-b63b-08f5aa137b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## So why did batch_size=32 work with GRU but not with LSTM?\n",
    "## GRU takes up less VRAM than LSTM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80abfd07-dcd2-4cbe-a72d-9926404e0e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 20s 263ms/step\n",
      "AUC: 0.98%\n"
     ]
    }
   ],
   "source": [
    "scores_gru = model_gru.predict(x_valid_pad)\n",
    "print(\"AUC: %.2f%%\" % (roc_auc(scores_gru, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee9ea6-5939-4eef-9df0-0ae35ef2e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WOW! Can I push this even further?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
