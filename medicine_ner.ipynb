{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69f1677-8883-43f6-9fb3-e49c9f7778ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"cointegrated/rubert-tiny2\"\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b0421a-98a1-4390-bd0a-45e3cedd82d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallirium/dostNN/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from corus import load_rudrec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter, defaultdict\n",
    "from razdel import tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ea11e0-6210-413a-b582-ddbe61aad595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4809\n",
      "–î–æ–±—Ä–æ–π –Ω–æ—á–∏ –¥–æ—Ä–æ–≥–∏–µ –¥—Ä—É–∑—å—è –∏ –ø—Ä–æ—Å—Ç–æ —á–∏—Ç–∞—Ç–µ–ª–∏.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drugs = list(load_rudrec('rudrec_annotated.json'))\n",
    "print(len(drugs))\n",
    "print(drugs[10].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c73a6ca6-1565-4214-8d74-52f538f2f320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DI 1401\n",
      "[('–ø—Ä–æ—Å—Ç—É–¥—ã', 64), ('–û–†–í–ò', 47), ('–ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∏', 42)]\n",
      "Drugname 1043\n",
      "[('–í–∏—Ñ–µ—Ä–æ–Ω', 33), ('–ê–Ω–∞—Ñ–µ—Ä–æ–Ω', 25), ('–¶–∏–∫–ª–æ—Ñ–µ—Ä–æ–Ω', 24)]\n",
      "Drugform 836\n",
      "[('—Ç–∞–±–ª–µ—Ç–∫–∏', 154), ('—Ç–∞–±–ª–µ—Ç–æ–∫', 79), ('—Å–≤–µ—á–∏', 63)]\n",
      "ADR 720\n",
      "[('–∞–ª–ª–µ—Ä–≥–∏—è', 16), ('—Å–ª–∞–±–æ—Å—Ç—å', 13), ('–¥–∏–∞—Ä–µ—è', 12)]\n",
      "Drugclass 330\n",
      "[('–ø—Ä–æ—Ç–∏–≤–æ–≤–∏—Ä—É—Å–Ω—ã–π', 21), ('–ø—Ä–æ—Ç–∏–≤–æ–≤–∏—Ä—É—Å–Ω–æ–µ', 18), ('–ø—Ä–æ—Ç–∏–≤–æ–≤–∏—Ä—É—Å–Ω—ã—Ö', 13)]\n",
      "Finding 236\n",
      "[('–∞–ª–ª–µ—Ä–≥–∏–∏', 12), ('—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã', 6), ('—Å–æ–Ω–ª–∏–≤–æ—Å—Ç–∏', 5)]\n"
     ]
    }
   ],
   "source": [
    "type2text = defaultdict(Counter)\n",
    "ents = Counter()\n",
    "for item in drugs:\n",
    "    for e in item.entities:\n",
    "        ents[e.entity_type] += 1\n",
    "        type2text[e.entity_type][e.entity_text] += 1\n",
    "\n",
    "for k, v in ents.most_common():\n",
    "    print(k, v)\n",
    "    print(type2text[k].most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "423dc2b4-30ef-4551-a347-6203b3dc3d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(item):\n",
    "    raw_toks = list(tokenize(item.text))\n",
    "    words = [tok.text for tok in raw_toks]\n",
    "    word_labels = [\"O\"] * len(raw_toks)\n",
    "    char2word = [None] * len(item.text)\n",
    "    for i, word in enumerate(raw_toks):\n",
    "        char2word[word.start:word.stop] = [i] * len(word.text)\n",
    "\n",
    "\n",
    "    for e in item.entities:\n",
    "        e_words = sorted({idx for idx in char2word[e.start:e.end] if idx is not None})\n",
    "        word_labels[e_words[0]] = \"B-\" + e.entity_type\n",
    "        for idx in e_words[1:]:\n",
    "            word_labels[idx] = \"I-\" + e.entity_type\n",
    "\n",
    "    return {\"tokens\": words,\"tags\": word_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31167be4-b48e-46db-bfeb-31682778f82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['–Ω–∞–º',\n",
       "  '–ø—Ä–æ–ø–∏—Å–∞–ª–∏',\n",
       "  ',',\n",
       "  '—Ç–∞–∫',\n",
       "  '–º–æ–π',\n",
       "  '—Ä–µ–±–µ–Ω–æ–∫',\n",
       "  '—Å—ã–ø—å—é',\n",
       "  '–ø–æ–∫—Ä—ã–ª—Å—è',\n",
       "  ',',\n",
       "  '–≥–ª–∞–∑–∞',\n",
       "  '–æ–ø—É—Ö–ª–∏',\n",
       "  ',',\n",
       "  '—Å–≤–µ—Ä—Ö—É',\n",
       "  '–∏',\n",
       "  '—Å–Ω–∏–∑—É',\n",
       "  '–Ω–∞',\n",
       "  '–≤–µ–∫–∞—Ö',\n",
       "  '–≤—ã—Å—ã–ø–∞–ª–∞',\n",
       "  '—Å—ã–ø—å',\n",
       "  ',',\n",
       "  '(',\n",
       "  '8',\n",
       "  '–º–µ—Å—è—Ü–µ–≤',\n",
       "  '—Å—ã–Ω—É',\n",
       "  ')',\n",
       "  '–ê',\n",
       "  '–æ—Ç',\n",
       "  '–≤–∏—Ñ–µ—Ä–æ–Ω–∞',\n",
       "  '—Ç–∞–∫–æ–≥–æ',\n",
       "  '–Ω–µ',\n",
       "  '–±—ã–ª–æ',\n",
       "  '...',\n",
       "  '–£',\n",
       "  '–∫–æ–≥–æ',\n",
       "  '–µ—â—ë',\n",
       "  '—Ç–∞–∫–∏–µ',\n",
       "  '–ø–æ–±–æ—á–∫–∏',\n",
       "  ',',\n",
       "  '–æ—Ç–∑–æ–≤–∏—Ç–µ—Å—å',\n",
       "  '!',\n",
       "  '1',\n",
       "  '–ß–µ–º',\n",
       "  '—Å–ø–∞—Å–∞–ª–∏—Å—å',\n",
       "  '?'],\n",
       " 'tags': ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-ADR',\n",
       "  'I-ADR',\n",
       "  'O',\n",
       "  'B-ADR',\n",
       "  'I-ADR',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-ADR',\n",
       "  'I-ADR',\n",
       "  'I-ADR',\n",
       "  'I-ADR',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-Drugform',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_labels(drugs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc3211a-4f0b-4cf0-aed1-1eef7a0222e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_data = [extract_labels(item) for item in drugs]\n",
    "ner_train, ner_test = train_test_split(ner_data, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c98433e-af2c-42ac-bdbe-8c132b1cfd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>[–ù–∞, —Å–ª–µ–¥—É—é—â—É—é, –Ω–æ—á—å, —Å–≤–µ—á–∫–∏, —É–∂–µ, –Ω–∏–∫–∞–∫–∏–µ, –Ω–µ...</td>\n",
       "      <td>[O, O, O, B-Drugform, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>[–Ω–∏, —Å–ª–æ–≤–∞, —Å–∫–∞–∑–∞—Ç—å, –Ω–µ, –º–æ–≥, ,, –¥–∞–∂–µ, –ø–æ—à–µ–≤–µ–ª...</td>\n",
       "      <td>[B-ADR, I-ADR, I-ADR, I-ADR, I-ADR, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>[–°—Ç–æ—è—Ç, —Ç–∞–±–ª–µ—Ç–∫–∏, –Ω–µ–¥–æ—Ä–æ–≥–æ, ,, –Ω–æ, –ø—Ä–µ–ø–∞—Ä–∞—Ç, –Ω...</td>\n",
       "      <td>[O, B-Drugform, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "2590  [–ù–∞, —Å–ª–µ–¥—É—é—â—É—é, –Ω–æ—á—å, —Å–≤–µ—á–∫–∏, —É–∂–µ, –Ω–∏–∫–∞–∫–∏–µ, –Ω–µ...   \n",
       "1491  [–Ω–∏, —Å–ª–æ–≤–∞, —Å–∫–∞–∑–∞—Ç—å, –Ω–µ, –º–æ–≥, ,, –¥–∞–∂–µ, –ø–æ—à–µ–≤–µ–ª...   \n",
       "740   [–°—Ç–æ—è—Ç, —Ç–∞–±–ª–µ—Ç–∫–∏, –Ω–µ–¥–æ—Ä–æ–≥–æ, ,, –Ω–æ, –ø—Ä–µ–ø–∞—Ä–∞—Ç, –Ω...   \n",
       "\n",
       "                                                 tags  \n",
       "2590    [O, O, O, B-Drugform, O, O, O, O, O, O, O, O]  \n",
       "1491  [B-ADR, I-ADR, I-ADR, I-ADR, I-ADR, O, O, O, O]  \n",
       "740              [O, B-Drugform, O, O, O, O, O, O, O]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ner_train).sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01b63030-6042-4140-8a91-8d9f0b0b1040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-ADR', 'B-DI', 'B-Drugclass', 'B-Drugform', 'B-Drugname', 'B-Finding', 'I-ADR', 'I-DI', 'I-Drugclass', 'I-Drugform', 'I-Drugname', 'I-Finding']\n"
     ]
    }
   ],
   "source": [
    "label_list = sorted({label for item in ner_train for label in item['tags']})\n",
    "if 'O' in label_list:\n",
    "    label_list.remove('O')\n",
    "    label_list = ['O'] + label_list\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0688cf0c-b12f-4335-bd9c-0fe88ed6d0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 3847\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 962\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallirium/dostNN/lib/python3.11/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "ner_data = DatasetDict({\n",
    "    'train': Dataset.from_pandas(pd.DataFrame(ner_train)),\n",
    "    'test': Dataset.from_pandas(pd.DataFrame(ner_test))    \n",
    "})\n",
    "print(ner_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea8aeeaf-ce09-48f0-b0c7-553f7d5fe9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0a191ab-9b4a-4c58-ae26-29f034ed585a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 9944, 1419, 3], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1bbf915-e667-4548-b7f3-1f9dc6037765",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ner_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5430eebe-3ff3-4da3-9798-a22a163eaa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '–ú—ã', '–ø–æ–º–µ–Ω—è–ª–∏', '–º–µ—Å—Ç–æ', '–∂–∏—Ç–µ–ª—å—Å—Ç–≤–∞', '–∏', '–ø–µ—Ä–µ–≤–µ–ª–∏', '–¥–æ—á—å', '–≤', '—à–∫–æ–ª—É', ',', '–∫–æ—Ç–æ—Ä–∞—è', '–Ω–∞—Ö–æ–¥–∏—Ç—Å—è', '–±–ª–∏–∂–µ', '–∫', '–¥–æ–º—É', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(sent[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90ef8503-4561-4c48-8f8d-67b7febf1a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for i, label in enumerate(examples['tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids =  []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "    \n",
    "        label_ids = [label_list.index(idx) if isinstance(idx, str) else idx for idx in label_ids]\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b9f68cb-4685-492f-b53a-71a6f880fe5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[2, 1041, 37038, 33265, 19106, 40305, 22018, 548, 22276, 320, 21538, 16, 47886, 548, 59614, 11137, 626, 56606, 700, 18, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 0, 1, 1, 7, 7, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_and_align_labels(ner_data['train'][22:23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4909f7c-1ca3-40fa-a373-17b6217604d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3847/3847 [00:00<00:00, 14181.13 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 962/962 [00:00<00:00, 26485.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = ner_data.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fb66c41-68b8-4306-9927-0e0a3d9be61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))\n",
    "model.config.id2label = dict(enumerate(label_list))\n",
    "model.config.label2id = {v: k for k, v in model.config.id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "345bf0b9-0536-4309-b50d-d797ec2ed7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"ner\",\n",
    "    evaluation_strategy = 'epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='no',\n",
    "    report_to='none',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d965f853-e8e6-4cf9-bf77-37a1c06598e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41080/4079666221.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18d770a7-9a47-45d7-a500-803a79035df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DI': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'Drugform': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=[ner_train[4]['tags']], references=[ner_train[4]['tags']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e97b4272-58a5-42f4-a4fb-6ed6d3fb61ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels, zero_division=0)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3febe98-8de4-4de3-bc0c-a3ebea214947",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2142d9a3-faea-4ed3-814e-906caed1ec6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='122' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.6721551418304443,\n",
       " 'eval_precision': 0.016947875866224767,\n",
       " 'eval_recall': 0.11375126390293225,\n",
       " 'eval_f1': 0.029500458896027273,\n",
       " 'eval_accuracy': 0.06463173504695996,\n",
       " 'eval_runtime': 0.6238,\n",
       " 'eval_samples_per_second': 1542.049,\n",
       " 'eval_steps_per_second': 97.781}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d50de629-8c03-4519-b89b-b6676e5080c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66bbe0dd-a899-4f89-8739-af76035fc903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2410' max='2410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2410/2410 00:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.437829</td>\n",
       "      <td>0.641841</td>\n",
       "      <td>0.387765</td>\n",
       "      <td>0.483454</td>\n",
       "      <td>0.889212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.352718</td>\n",
       "      <td>0.592048</td>\n",
       "      <td>0.549545</td>\n",
       "      <td>0.570005</td>\n",
       "      <td>0.905648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.311709</td>\n",
       "      <td>0.645610</td>\n",
       "      <td>0.609707</td>\n",
       "      <td>0.627145</td>\n",
       "      <td>0.915843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.290050</td>\n",
       "      <td>0.657375</td>\n",
       "      <td>0.655713</td>\n",
       "      <td>0.656543</td>\n",
       "      <td>0.920539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>0.276298</td>\n",
       "      <td>0.631989</td>\n",
       "      <td>0.697169</td>\n",
       "      <td>0.662981</td>\n",
       "      <td>0.923443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>0.265435</td>\n",
       "      <td>0.666027</td>\n",
       "      <td>0.701719</td>\n",
       "      <td>0.683407</td>\n",
       "      <td>0.927706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.261459</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>0.728008</td>\n",
       "      <td>0.690979</td>\n",
       "      <td>0.929004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.256533</td>\n",
       "      <td>0.670093</td>\n",
       "      <td>0.724975</td>\n",
       "      <td>0.696455</td>\n",
       "      <td>0.930672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.206800</td>\n",
       "      <td>0.256405</td>\n",
       "      <td>0.657596</td>\n",
       "      <td>0.733064</td>\n",
       "      <td>0.693282</td>\n",
       "      <td>0.929869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.206800</td>\n",
       "      <td>0.255454</td>\n",
       "      <td>0.666820</td>\n",
       "      <td>0.730536</td>\n",
       "      <td>0.697226</td>\n",
       "      <td>0.931105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2410, training_loss=0.3037856200918617, metrics={'train_runtime': 45.2163, 'train_samples_per_second': 850.799, 'train_steps_per_second': 53.299, 'total_flos': 24794241657930.0, 'train_loss': 0.3037856200918617, 'epoch': 10.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c79ca344-32dc-4f71-bfff-436c800b24c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.25545403361320496,\n",
       " 'eval_precision': 0.6668204891555145,\n",
       " 'eval_recall': 0.7305358948432761,\n",
       " 'eval_f1': 0.6972255729794934,\n",
       " 'eval_accuracy': 0.9311047948591201,\n",
       " 'eval_runtime': 0.3374,\n",
       " 'eval_samples_per_second': 2851.596,\n",
       " 'eval_steps_per_second': 180.818,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23f5ec72-3884-41bd-bbe5-ece614a46f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADR': {'precision': 0.2736318407960199, 'recall': 0.22727272727272727, 'f1': 0.24830699774266363, 'number': 242}, 'DI': {'precision': 0.4041916167664671, 'recall': 0.6367924528301887, 'f1': 0.49450549450549447, 'number': 424}, 'Drugclass': {'precision': 0.8260869565217391, 'recall': 0.8769230769230769, 'f1': 0.8507462686567164, 'number': 195}, 'Drugform': {'precision': 0.8794326241134752, 'recall': 0.8888888888888888, 'f1': 0.8841354723707666, 'number': 279}, 'Drugname': {'precision': 0.8665018541409147, 'recall': 0.9422043010752689, 'f1': 0.9027688345138442, 'number': 744}, 'Finding': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 94}, 'overall_precision': 0.6668204891555145, 'overall_recall': 0.7305358948432761, 'overall_f1': 0.6972255729794934, 'overall_accuracy': 0.9311047948591201}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gallirium/dostNN/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a33737d6-a62e-4d93-8d58-a648df55520a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O</th>\n",
       "      <th>B-ADR</th>\n",
       "      <th>B-DI</th>\n",
       "      <th>B-Drugclass</th>\n",
       "      <th>B-Drugform</th>\n",
       "      <th>B-Drugname</th>\n",
       "      <th>B-Finding</th>\n",
       "      <th>I-ADR</th>\n",
       "      <th>I-DI</th>\n",
       "      <th>I-Drugclass</th>\n",
       "      <th>I-Drugform</th>\n",
       "      <th>I-Drugname</th>\n",
       "      <th>I-Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>13478</td>\n",
       "      <td>18</td>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ADR</th>\n",
       "      <td>70</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-DI</th>\n",
       "      <td>76</td>\n",
       "      <td>19</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Drugclass</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Drugform</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Drugname</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-Finding</th>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ADR</th>\n",
       "      <td>93</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-DI</th>\n",
       "      <td>107</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Drugclass</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Drugform</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Drugname</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-Finding</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 O  B-ADR  B-DI  B-Drugclass  B-Drugform  B-Drugname  \\\n",
       "O            13478     18    85           20          22          51   \n",
       "B-ADR           70     77    82            1           0           5   \n",
       "B-DI            76     19   301            3           6           9   \n",
       "B-Drugclass     19      0     4          171           1           0   \n",
       "B-Drugform      29      0     1            0         249           0   \n",
       "B-Drugname      17      0     6            2           3         715   \n",
       "B-Finding       23     16    51            3           0           1   \n",
       "I-ADR           93     23    22            0           0           0   \n",
       "I-DI           107     10    63            0           0           2   \n",
       "I-Drugclass      0      0     0            2           0           0   \n",
       "I-Drugform       3      0     0            0           0           0   \n",
       "I-Drugname      10      0     2            1           1          26   \n",
       "I-Finding        7      3    12            4           0           0   \n",
       "\n",
       "             B-Finding  I-ADR  I-DI  I-Drugclass  I-Drugform  I-Drugname  \\\n",
       "O                    0      7    18            0           0           0   \n",
       "B-ADR                0      4     3            0           0           0   \n",
       "B-DI                 0      0    10            0           0           0   \n",
       "B-Drugclass          0      0     0            0           0           0   \n",
       "B-Drugform           0      0     0            0           0           0   \n",
       "B-Drugname           0      0     1            0           0           0   \n",
       "B-Finding            0      0     0            0           0           0   \n",
       "I-ADR                0     39    32            0           0           0   \n",
       "I-DI                 0      3    39            0           0           0   \n",
       "I-Drugclass          0      0     0            0           0           0   \n",
       "I-Drugform           0      0     0            0           0           0   \n",
       "I-Drugname           0      0     0            0           0           0   \n",
       "I-Finding            0      1     2            0           0           0   \n",
       "\n",
       "             I-Finding  \n",
       "O                    0  \n",
       "B-ADR                0  \n",
       "B-DI                 0  \n",
       "B-Drugclass          0  \n",
       "B-Drugform           0  \n",
       "B-Drugname           0  \n",
       "B-Finding            0  \n",
       "I-ADR                0  \n",
       "I-DI                 0  \n",
       "I-Drugclass          0  \n",
       "I-Drugform           0  \n",
       "I-Drugname           0  \n",
       "I-Finding            0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(sum(true_labels, []), sum(true_predictions, []), labels=label_list),\n",
    "    index=label_list,\n",
    "    columns=label_list\n",
    ")\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f3e43d7-d276-4f62-913b-6ad614bffe4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ner_bert.bin/tokenizer_config.json',\n",
       " 'ner_bert.bin/special_tokens_map.json',\n",
       " 'ner_bert.bin/vocab.txt',\n",
       " 'ner_bert.bin/added_tokens.json',\n",
       " 'ner_bert.bin/tokenizer.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('ner_bert.bin')\n",
    "tokenizer.save_pretrained('ner_bert.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "791f2b09-13ee-486c-8373-5d44e6051ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–•–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è —Å –≤–∞–º–∏ –æ—Ç–∑—ã–≤–æ–º –æ —Å–Ω–æ—Ç–≤–æ—Ä–Ω—ã—Ö —Ç–∞–±–ª–µ—Ç–∫–∞—Ö \" –ö—Ä–∞—Å–Ω–∞—è –∑–≤–µ–∑–¥–∞ \" –°–æ–Ω–¥–æ–∫—Å , –∫–æ—Ç–æ—Ä—ã–µ —è –ø—Ä–∏–æ–±—Ä–µ–ª–∞ –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –º–æ–µ–π –ø–æ–¥—Ä—É–≥–∏ .'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "text = ' '.join(ner_test[7][\"tokens\"])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6f08651-7f7e-42ad-8e41-d6262a0b41e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ents(text):\n",
    "    tokens = tokenizer(text, return_tensors='pt')\n",
    "    tokens = {k: v.to(model.device) for k, v in tokens.items()}\n",
    "    with torch.no_grad():\n",
    "        pred = model(**tokens)\n",
    "    indices = pred.logits.argmax(dim=-1)[0].cpu().numpy()\n",
    "    token_text = tokenizer.convert_ids_to_tokens(tokens['input_ids'][0])\n",
    "    for t, idx in zip(token_text, indices):\n",
    "        print(f\"{t:15s} {label_list[idx]:10s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b639d0ea-efa4-4e84-8a68-966bfa4975c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           O         \n",
      "–°–ª–æ–≤            O         \n",
      "##–∏–ª            O         \n",
      "—Ç—É—Ç             O         \n",
      "–ú–∏—à–∞            O         \n",
      "–Ω–∞              O         \n",
      "–Ω–µ–¥–µ–ª–µ          O         \n",
      "–≥–∞—Å—Ç—Ä           B-DI      \n",
      "##–∏—Ç            B-DI      \n",
      ".               O         \n",
      "–ú–∏—à–∞            O         \n",
      "—Å–∏–ª—å–Ω–æ          O         \n",
      "–ø–æ—Å—Ç—Ä–∞–¥–∞–ª       O         \n",
      ",               O         \n",
      "–Ω–æ–≥–∏            O         \n",
      "–∏               O         \n",
      "—Ä—É–∫–∏            O         \n",
      "–±–æ–ª–µ–ª–∏          O         \n",
      "–¥–∞–∂–µ            O         \n",
      ".               O         \n",
      "–¢–∞–±–ª            B-Drugform\n",
      "##–µ—Ç–∫–∏          B-Drugform\n",
      "–∏               O         \n",
      "—É—Å–ø–æ–∫–æ          B-Drugclass\n",
      "##–∏—Ç–µ–ª—å–Ω—ã–µ      B-Drugclass\n",
      "–ø—Ä–∏—à–ª–æ—Å—å        O         \n",
      "–ø–∏—Ç—å            O         \n",
      ".               O         \n",
      "[SEP]           O         \n"
     ]
    }
   ],
   "source": [
    "predict_ents(\"–°–ª–æ–≤–∏–ª —Ç—É—Ç –ú–∏—à–∞ –Ω–∞ –Ω–µ–¥–µ–ª–µ –≥–∞—Å—Ç—Ä–∏—Ç. –ú–∏—à–∞ —Å–∏–ª—å–Ω–æ –ø–æ—Å—Ç—Ä–∞–¥–∞–ª, –Ω–æ–≥–∏ –∏ —Ä—É–∫–∏ –±–æ–ª–µ–ª–∏ –¥–∞–∂–µ. –¢–∞–±–ª–µ—Ç–∫–∏ –∏ —É—Å–ø–æ–∫–æ–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏—à–ª–æ—Å—å –ø–∏—Ç—å.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230ef55-2805-49a2-b77f-f8c482db5e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dostNN",
   "language": "python",
   "name": "dostnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
